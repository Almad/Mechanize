<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
        "http://www.w3.org/TR/html4/strict.dtd">
@# This file is processed by EmPy: do not edit
@# http://wwwsearch.sf.net/bits/colorize.py
@{from colorize import colorize}
@{import time}
@{import release}
@{last_modified = release.svn_id_to_time("$Id$")}
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
  <meta name="author" content="John J. Lee &lt;jjl@@pobox.com&gt;">
  <meta name="date" content="@(time.strftime("%Y-%m-%d", last_modified))">
  <meta name="keywords" content="Python,HTML,browser,stateful,web,client,client-side,mechanize,form,ClientForm,ClientCookie,pullparser,WWW::Mechanize">
  <title>mechanize</title>
  <style type="text/css" media="screen">@@import "../styles/style.css";</style>
  <base href="http://wwwsearch.sourceforge.net/mechanize/">
</head>
<body>

<div id="sf"><a href="http://sourceforge.net">
<img src="http://sourceforge.net/sflogo.php?group_id=48205&amp;type=2"
 width="125" height="37" alt="SourceForge.net Logo"></a></div>
<!--<img src="../images/sflogo.png"-->

<h1>mechanize</h1>

<div id="Content">

<p>Stateful programmatic web browsing in Python, after Andy Lester's Perl
module <a
href="http://search.cpan.org/dist/WWW-Mechanize/"><code>WWW::Mechanize</code>
</a>.

<ul>
  <li><code>mechanize.Browser</code> is a subclass of
    <code>mechanize.UserAgent</code>, which is, in turn, a subclass of
    urllib2.OpenerDirector (<code>ClientCookie.OpenerDirector</code> for
    pre-2.4 versions of Python), so any URL can be opened, not just
    <code>http:</code>.  <code>mechanize.UserAgent</code> offers easy dynamic
    configuration of user-agent features like protocol, cookie, redirection and
    <code>robots.txt</code> handling, without having to make a new
    <code>OpenerDirector</code> each time, eg.  by calling
    <code>build_opener()</code> (it's not stable yet, though).
  <li>Easy HTML form filling, using <a href="../ClientForm/">ClientForm</a>
    interface.
  <li>Convenient link parsing and following.
  <li>Browser history (<code>.back()</code> and <code>.reload()</code>
    methods).
  <li>The <code>Referer</code> HTTP header is added properly (optional).
  <li>Automatic observance of <a
    href="http://www.robotstxt.org/wc/norobots.html">
    <code>robots.txt</code></a>.


</ul>

<p>An example:

@{colorize(r"""
import re
from mechanize import Browser

br = Browser()
br.open("http://www.example.com/")
# follow second link with element text matching regular expression
response = br.follow_link(text_regex=re.compile(r"cheese\s*shop"), nr=1)
assert br.viewing_html()
print br.title()
print response.geturl()
print response.info()  # headers
print response.read()  # body
response.close()

br.select_form(name="order")
# Browser passes through unknown attributes (including methods)
# to the selected HTMLForm (from ClientForm).
br["cheeses"] = ["mozzarella", "caerphilly"]  # (the method here is __setitem__)
response2 = br.submit()  # submit current form

response3 = br.back()  # back to cheese shop
# the history mechanism uses cached requests and responses
assert response3 is response
# we can still use the response, even though we closed it:
response3.seek(0)
response3.read()
response4 = br.reload()
assert response4 is not response3

for form in br.forms():
    print form
# .links() optionally accepts the keyword args of .follow_/.find_link()
for link in br.links(url_regex=re.compile("python.org")):
    print link
    br.follow_link(link)  # takes EITHER Link instance OR keyword args
    br.back()
""")}

<p>You may control the browser's policy by using the methods of
<code>mechanize.Browser</code>'s base class, <code>mechanize.UserAgent</code>.
For example:

@{colorize("""
br = Browser()
# Don't handle HTTP-EQUIV headers (HTTP headers embedded in HTML).
br.set_handle_equiv(False)
# Ignore robots.txt.  Do not do this without thought and consideration.
br.set_handle_robots(False)
# Don't handle cookies
br.set_cookiejar()
# Supply your own ClientCookie.CookieJar (NOTE: cookie handling is ON by
# default: no need to do this unless you have some reason to use a
# particular cookiejar)
br.set_cookiejar(cj)
# Print information about HTTP redirects and Refreshes.
br.set_debug_redirects(True)
# Print HTTP response bodies (ie. the HTML, most of the time).
br.set_debug_responses(True)
# Print HTTP headers.
br.set_debug_http(True)
""")}

<p>Full documentation is in the docstrings.

<p>Thanks to Ian Bicking, for persuading me that a <code>UserAgent</code> class
would be useful.


<h2>Todo</h2>

<ul>
 <li>Fix <code>.response()</code> method (each call should return independent
   pointer to same data).  Want to be able to clone responses, too, so can
   process HTML.  Needs some careful thought: want to clean up the multiple
   layers of response objects in ClientCookie and the standard library.
 <li>Stabilise <code>mechanize.UserAgent</code>.
 <li>Test with non-http URLs.
 <li>Remove dependency on pullparser: it's broken .
 <li>History cache expiration.
 <li>Add <code>Browser.load_response()</code> method.
 <li>Add <code>Browser.form_as_string()</code> and
   <code>Browser.__str__()</code> methods.
 <li>Combine ClientForm, ClientCookie and mechanize in a single download.
 <li>Would be nice to add an implementation of ClientForm interface built on
   something like BeautifulSoup, which would allow easy &quot;escape&quot; to
   the lower-level BeautifulSoup API in cases where the higher-level
   <code>mechanize.Browser</code> / ClientForm API is not sufficient.  (DOMForm
   is similar: implementation of ClientForm interface on top of HTML DOM, but
   it's buggy and unmaintained, and the DOM is not as nice an API as
   BeautifulSoup).
 <li>Add some utilities useful for testing (eg. fetch images and stylesheets in
   page, easy assertion of things like: cookies sent by server, redirections,
   HTTP error codes etc.).
 <li>Do auth and proxies properly (ClientCookie probably needs some work here,
   too -- and maybe urllib2 also).  Need to configure local squid and apache,
   yawn...
</ul>


<a name="download"></a>
<h2>Download</h2>
<p>All documentation (including this web page) is included in the distribution.

<p>This is an alpha release: interfaces may change, and there will be bugs.

<p><em>Development release.</em>

<ul>
<li><a href="./src/mechanize-0.0.9a.tar.gz">mechanize-0.0.9a.tar.gz</a>
<li><a href="./src/mechanize-0_0_9a.zip">mechanize-0_0_9a.zip</a>
<li><a href="./src/ChangeLog.txt">Change Log</a> (included in distribution)
<li><a href="./src/">Older versions.</a>
</ul>

<p>For installation instructions, see the INSTALL file included in the
distribution.

<h2>See also</h2>

<p>Richard Jones' <a href="http://mechanicalcat.net/tech/webunit/">webunit</a>
(this is not the same as Steven Purcell's <a
href="http://webunit.sourceforge.net/">code of the same name</a>).  webunit and
mechanize are quite similar.  On the minus side, webunit is missing things like
browser history, high-level forms and links handling, thorough cookie handling,
refresh redirection, adding of the Referer header, observance of robots.txt and
easy extensibility.  On the plus side, webunit has a bunch of utility functions
bound up in its WebFetcher class, which look useful for writing tests (though
they'd be easy to duplicate using mechanize).  In general, webunit has more of
a frameworky emphasis, with aims limited to writing tests, where mechanize and
the modules it depends on try hard to be general-purpose libraries.

<p>There are many related links in the <a
href="../bits/GeneralFAQ.html">General FAQ</a> page, too.


<a name="faq"></a>
<h2>FAQs</h2>
<ul>
  <li>Which version of Python do I need?
  <p>2.2 or above.
  <li>What else do I need?
  <p><a href="../ClientCookie/">ClientCookie</a> 1.0.2 or newer,
   <a href="../ClientForm/">ClientForm</a> 0.1.7, and
   <a href="../pullparser/">pullparser</a> 0.0.4b or newer.
  <li>Which license?
  <p>The <a href="http://www.opensource.org/licenses/bsd-license.php">
   BSD license</a> (included in distribution).
</ul>

<p>I prefer questions and comments to be sent to the <a
href="http://lists.sourceforge.net/lists/listinfo/wwwsearch-general">
mailing list</a> rather than direct to me.

<p><a href="mailto:jjl@@pobox.com">John J. Lee</a>,
@(time.strftime("%B %Y", last_modified)).

<hr>

</div>

<div id="Menu">

@(release.navbar('mechanize'))

<br>

<a href="./#download">Download</a><br>
<a href="./#faq">FAQs</a><br>

</div>


</body>
</html>
